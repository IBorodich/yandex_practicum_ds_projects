# Определение токсичных комментариев

## Задача

Для интернет-магазина необходимо было построить модель, которая бы определяла токсичные комментарии и отправляла их на модерацию. Значение F1-мера должно быть не менее 0,75. Проект решался двумя способами: 
- С использованием TF-IDF
- С использованием эмбеддингов (BERT)

## Данные

В нашем распоряжении были следующие исторические данные: 
- text - текст комментария
- toxic - целевой признак (разметка токсичных и нетоксичных комментариев)

## Используемые библиотеки
- pandas
- numpy
- spacy
- nltk
- torch
- transformers
- sklearn
- catboost

## Основные этапы проекта
1. С использованием TF-IDF:
- лемматизация текста при помощи библиотеки spacy;
- очистка данных от спецсимволов и цифр при помощи регулярных выражений и незначащих слов (стоп-слов) при помощи библиотеки nltk;
- векторизация текста и создание признаков при помощи TF-IDF из библиотеки sklearn.
2. С использованием эмбеддингов (BERT):
- токенизация, лемматизация текста и создание признаков (эмбеддингов) при помощи модели BERT из библиотеки transformers.

## Результат
Значение F1-мера на тестовой выборке для модели CatBoostClassifier составило:
- С использованием TF-IDF: 0,75
- С использованием эмбеддингов (BERT): 0,90
