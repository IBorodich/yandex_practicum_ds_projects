# Определение токсичных комментариев

## Задача

Для интернет-магазина необходимо было построить модель, которая бы определяла токсичные комментарии и отправляла их на модерацию. Значение F1-мера должно быть не менее 0,75. Задача решалась с использованием TF-IDF.

## Данные

В нашем распоряжении были следующие исторические данные: 
- text - текст комментария
- toxic - целевой признак (разметка токсичных и нетоксичных комментариев)

## Используемые библиотеки
- pandas
- numpy
- spacy
- nltk
- sklearn
- catboost

## Основные этапы проекта
- лемматизация текста при помощи библиотеки spacy;
- очистка данных от спецсимволов и цифр при помощи регулярных выражений и незначащих слов (стоп-слов) при помощи библиотеки nltk;
- векторизация текста и создание признаков при помощи TF-IDF из библиотеки sklearn.
- 
## Результат
Значение F1-меры на тестовой выборке для модели CatBoostClassifier составило 0,76.
